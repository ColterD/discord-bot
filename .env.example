# =============================================================================
# Discord Bot Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# All env vars are optional with sensible defaults unless marked [REQUIRED]
# =============================================================================

# -----------------------------------------------------------------------------
# Discord Configuration [REQUIRED]
# -----------------------------------------------------------------------------
# Bot token from Discord Developer Portal
DISCORD_TOKEN=your_discord_bot_token_here

# Application Client ID from Discord Developer Portal
DISCORD_CLIENT_ID=your_client_id_here

# Guild ID for development (guild commands update instantly)
# Leave empty for production (global commands)
DEV_GUILD_ID=your_dev_guild_id_here

# -----------------------------------------------------------------------------
# Environment
# -----------------------------------------------------------------------------
# 'development' | 'production'
NODE_ENV=development

# Logging level: DEBUG | INFO | WARN | ERROR
LOG_LEVEL=DEBUG

# -----------------------------------------------------------------------------
# LLM Configuration (Ollama)
# -----------------------------------------------------------------------------
# Ollama API endpoint
# Docker: http://ollama:11434 | Local: http://localhost:11434
OLLAMA_HOST=http://ollama:11434

# Model to use for chat
LLM_MODEL=hf.co/DavidAU/OpenAi-GPT-oss-20b-HERETIC-uncensored-NEO-Imatrix-gguf:Q5_1

# Max tokens for responses
LLM_MAX_TOKENS=4096

# Temperature (0.0-2.0, lower = more focused, higher = more creative)
LLM_TEMPERATURE=0.7

# Keep model in GPU memory (seconds, -1 = forever)
LLM_KEEP_ALIVE=300

# Preload model on startup (true/false)
LLM_PRELOAD=true

# Sleep after inactivity (milliseconds)
LLM_SLEEP_AFTER_MS=300000

# Use orchestrator for tool-aware conversations (true/false)
LLM_USE_ORCHESTRATOR=true

# HERETIC model specific settings
LLM_NUM_EXPERTS=5
LLM_REP_PEN=1.1
LLM_TEMP_CODING=0.6
LLM_TEMP_CREATIVE=1.0
LLM_CONTEXT_LENGTH=8192

# Summarization model (runs on CPU)
SUMMARIZATION_MODEL=qwen2.5:3b

# Embedding model for vector memory
EMBEDDING_MODEL=qwen3-embedding:0.6b

# -----------------------------------------------------------------------------
# Valkey (Redis-compatible cache)
# -----------------------------------------------------------------------------
VALKEY_URL=valkey://valkey:6379
VALKEY_CONVERSATION_TTL_MS=1800000
VALKEY_KEY_PREFIX=discord-bot:

# -----------------------------------------------------------------------------
# ChromaDB (Vector Store)
# -----------------------------------------------------------------------------
CHROMA_URL=http://chromadb:8000
CHROMA_COLLECTION=memories

# -----------------------------------------------------------------------------
# Memory Configuration
# -----------------------------------------------------------------------------
MEMORY_SUMMARIZE_AFTER_MESSAGES=15
MEMORY_SUMMARIZE_AFTER_IDLE_MS=1800000
MEMORY_MAX_CONTEXT_TOKENS=4096

# -----------------------------------------------------------------------------
# MCP (Model Context Protocol)
# -----------------------------------------------------------------------------
MCP_CONFIG_PATH=./mcp-servers.json
MCP_CONNECTION_TIMEOUT_MS=30000
MCP_REQUEST_TIMEOUT_MS=60000

# Docker MCP Gateway Configuration
# Transport type: "stdio" (default, recommended) or "sse" (legacy)
DOCKER_MCP_TRANSPORT=stdio
DOCKER_MCP_ENABLED=false

# SSE Transport Settings (only if DOCKER_MCP_TRANSPORT=sse)
DOCKER_MCP_GATEWAY_URL=http://host.docker.internal:8811
DOCKER_MCP_GATEWAY_ENDPOINT=/sse
DOCKER_MCP_BEARER_TOKEN=
DOCKER_MCP_AUTO_RECONNECT=true
DOCKER_MCP_MAX_RECONNECT_ATTEMPTS=5

# -----------------------------------------------------------------------------
# Security / Permissions
# -----------------------------------------------------------------------------
# Bot permission system (comma-separated Discord user IDs)
BOT_OWNER_IDS=your_discord_user_id_here
BOT_ADMIN_IDS=
BOT_MODERATOR_IDS=

# Impersonation detection
SECURITY_IMPERSONATION_ENABLED=true
SECURITY_SIMILARITY_THRESHOLD=0.7

# -----------------------------------------------------------------------------
# ComfyUI (Image Generation)
# -----------------------------------------------------------------------------
COMFYUI_URL=http://comfyui:8188
COMFYUI_MAX_QUEUE=5
COMFYUI_TIMEOUT=120000

# Inactivity timeout before unloading models from VRAM (milliseconds, default: 5 minutes)
COMFYUI_SLEEP_AFTER_MS=300000

# Whether to unload models when sleeping to free VRAM (true/false, default: true)
COMFYUI_UNLOAD_ON_SLEEP=true

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_REQUESTS=10
RATE_LIMIT_WINDOW_MS=60000

# -----------------------------------------------------------------------------
# Testing Configuration
# -----------------------------------------------------------------------------
# Master switch for test mode
TEST_MODE=false

# Webhook URL for automated testing
TEST_WEBHOOK_URL=

# Channels where bot responds to ALL messages (comma-separated)
TEST_CHANNEL_IDS=

# Enable verbose logging for test channels
TEST_VERBOSE_LOGGING=false

# Fake token pattern for unit tests (should be obviously fake but valid format)
TEST_DISCORD_TOKEN_PATTERN=MTIzNDU2Nzg5MDEyMzQ1Njc4OTAx.G12345._test_token_not_real_do_not_use_

# -----------------------------------------------------------------------------
# Troubleshooting Notes
# -----------------------------------------------------------------------------
# If you see "Failed to connect to OAuth notifications" errors:
#   docker mcp feature disable mcp-oauth-dcr
# This is a known issue (GitHub: docker/mcp-gateway#245)
